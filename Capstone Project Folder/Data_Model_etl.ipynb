{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Data_model for stock price prediction ETL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Select stocks to predict tommorrow's price "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a example, here I will use a list of five stocks from different industry/sector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f07e352514e4a4c8ce07870d564bd6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "import configparser\n",
    "spark = SparkSession.builder\\\n",
    "                     .config(\"spark.jars.packages\",\"org.apache.hadoop:hadoop-aws:2.7.0\")\\\n",
    "                     .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b441074f4c1471fadca9ff37d9eda49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83e834cfd84a4c6abae7052d4fcf40d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Package already installed for current Spark context!\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/context.py\", line 1110, in install_pypi_package\n",
      "    raise ValueError(\"Package already installed for current Spark context!\")\n",
      "ValueError: Package already installed for current Spark context!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sc.install_pypi_package(\"yfinance\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f91dec9fa351485a895674eeb770f07e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Package already installed for current Spark context!\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/context.py\", line 1110, in install_pypi_package\n",
      "    raise ValueError(\"Package already installed for current Spark context!\")\n",
      "ValueError: Package already installed for current Spark context!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sc.install_pypi_package(\"pyarrow\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18f045533e4f4b32837499f1f346afba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stocks=['AAPL', 'INTC', 'TSLA', 'GILD', 'BA']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Pull stocks data from yahoo finance and save to dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4906fc4bf2e54532b6da36d70aece867",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import pyarrow\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be194bfb3bd94813903192ac0e1bb22a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def download_current_stocks_to_df(stocks, ndays):\n",
    "    end=datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    start=(datetime.datetime.now()-datetime.timedelta(days=ndays)).strftime(\"%Y-%m-%d\")\n",
    "    stock_dict={}\n",
    "    for symbol in stocks:\n",
    "        df_symbol=yf.download(symbol,start,end,progress=False)\n",
    "        stock_dict.update({symbol:df_symbol})\n",
    "    return stock_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c09776a8d1ce40df866844f4ec879cba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stock_dict=download_current_stocks_to_df(stocks, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: scrape top news data of today or before market open"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is recommend to schedule the job just a little before market open (i.e. 9:30AM ET) to obtain the most recent news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd7d7e11025744fa92b44222ba9f9f0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting praw\n",
      "  Using cached https://files.pythonhosted.org/packages/5c/39/17251486951815d4514e4a3f179d4f3e7af5f7b1ce8eaba5a3ea61bc91f2/praw-7.0.0-py3-none-any.whl\n",
      "Collecting prawcore<2.0,>=1.3.0 (from praw)\n",
      "  Using cached https://files.pythonhosted.org/packages/c9/8e/d076cb8f26523f91eef3e75d6cf9143b2f16d67ce7d681a61d0bbc783f49/prawcore-1.3.0-py3-none-any.whl\n",
      "Collecting websocket-client>=0.54.0 (from praw)\n",
      "  Using cached https://files.pythonhosted.org/packages/4c/5f/f61b420143ed1c8dc69f9eaec5ff1ac36109d52c80de49d66e0c36c3dfdf/websocket_client-0.57.0-py2.py3-none-any.whl\n",
      "Collecting update-checker>=0.16 (from praw)\n",
      "  Using cached https://files.pythonhosted.org/packages/d6/c3/aaf8a162df8e8f9d321237c7c0e63aff95b42d19f1758f96606e3cabb245/update_checker-0.17-py2.py3-none-any.whl\n",
      "Requirement already satisfied: requests<3.0,>=2.6.0 in /mnt/tmp/1590649447296-0/lib/python3.7/site-packages (from prawcore<2.0,>=1.3.0->praw)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/site-packages (from websocket-client>=0.54.0->praw)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /mnt/tmp/1590649447296-0/lib/python3.7/site-packages (from requests<3.0,>=2.6.0->prawcore<2.0,>=1.3.0->praw)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /mnt/tmp/1590649447296-0/lib/python3.7/site-packages (from requests<3.0,>=2.6.0->prawcore<2.0,>=1.3.0->praw)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /mnt/tmp/1590649447296-0/lib/python3.7/site-packages (from requests<3.0,>=2.6.0->prawcore<2.0,>=1.3.0->praw)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /mnt/tmp/1590649447296-0/lib/python3.7/site-packages (from requests<3.0,>=2.6.0->prawcore<2.0,>=1.3.0->praw)\n",
      "Installing collected packages: prawcore, websocket-client, update-checker, praw\n",
      "Successfully installed praw-7.0.0 prawcore-1.3.0 update-checker-0.17 websocket-client-0.57.0"
     ]
    }
   ],
   "source": [
    "sc.install_pypi_package(\"praw\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a20292b21cf4f21b81ba42e0ce7b28b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#! usr/bin/env python3\n",
    "import praw\n",
    "import pandas as pd\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3cd686c70394d1dacb7a3a656bec3ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reddit = praw.Reddit(client_id='FbxkAEhvb7pxbg', \\\n",
    "                     client_secret='zyl8WnU9X5rr7y5_EeGUVj994kA', \\\n",
    "                     user_agent='topnewsscraper', \\\n",
    "                     username='xintao0202', \\\n",
    "                     password='zangma53@198422')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c2951d2e3bb4ed68eaa652c4f075e0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "subreddit = reddit.subreddit('worldnews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48393bab2baf468d8951b50bd79fb0c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "top_subreddit = subreddit.top(\"day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b978eadef837450b9d76104fc9e23ab7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "topics_dict = { \"title\":[], \"score\":[], \"created\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88e613c37db044ed944b54048ac41ce3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for submission in top_subreddit:\n",
    "    topics_dict[\"title\"].append(submission.title)\n",
    "    topics_dict[\"score\"].append(submission.score)\n",
    "#     topics_dict[\"id\"].append(submission.id)\n",
    "#     topics_dict[\"url\"].append(submission.url)\n",
    "#     topics_dict[\"comms_num\"].append(submission.num_comments)\n",
    "    topics_dict[\"created\"].append(dt.datetime.fromtimestamp(submission.created))\n",
    "#     topics_dict[\"body\"].append(submission.selftext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dffe524014d46db89450768ddf28c8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "topics_df = pd.DataFrame(topics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e281004813842ee8a947f98d74d1187",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title  score  \\\n",
      "0  The U.S. has certified that Hong Kong is no lo...  91856   \n",
      "1  Rio Tinto legally destroy Native Australian Ab...  35242   \n",
      "2  France bans use of hydroxychloroquine to cure ...   9240   \n",
      "3  Hong Kong police fire pepperballs at protester...   4324   \n",
      "4  Boris Johnson is tumbling in the polls after i...   4087   \n",
      "\n",
      "              created  \n",
      "0 2020-05-27 23:54:08  \n",
      "1 2020-05-28 06:27:39  \n",
      "2 2020-05-27 17:54:55  \n",
      "3 2020-05-27 15:33:52  \n",
      "4 2020-05-28 01:10:48"
     ]
    }
   ],
   "source": [
    "pd.set_option('max_columns', None)\n",
    "topics_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 Process stock and news data, and save thme to S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part of the data is for prediction. Once we trained a model, this is for predict. Instead of joining the dataframes together, it is better to keep them separated for DB storage and further analysis. The most current data will be pulled daily using Airflow, save them to S3 as well as load to Redshift cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similary as historical data, we will add technical indicators to stock data. The reason why we don't just pull one day stock is to calculate the technical indicators, which needs n days. Here I set n<30 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66dcdb87bb01492ca3081d6a2275dd1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_bbands(df, ndays):\n",
    "    dm = df[['Close']].rolling(ndays).mean()\n",
    "    ds = df[['Close']].rolling(ndays).std()\n",
    "    df['upperBB'] = dm + 2 * ds\n",
    "    df['lowerBB'] = dm - 2 * ds\n",
    "    return df\n",
    "\n",
    "# Simple Moving Average\n",
    "def get_SMA(df, ndays):\n",
    "    df['SMA']=df[['Close']].rolling(ndays).mean()\n",
    "    return df\n",
    "\n",
    "# Expontential Moving Average\n",
    "def get_EMA(df, ndays):\n",
    "    df['EMA'] = df[['Close']].ewm( span = ndays, min_periods = ndays - 1).mean()\n",
    "    return df\n",
    "\n",
    "# Rate of Change\n",
    "def get_ROC(df, ndays):\n",
    "    dn = df[['Close']].diff(ndays)\n",
    "    dd = df[['Close']].shift(ndays)\n",
    "    df['ROC'] = dn/dd\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04a618f61ac34648ae81496467e9f082",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def save_to_s3(df, stock, folder):\n",
    "    df_copy=df.copy()\n",
    "    df_copy.reset_index(inplace=True)\n",
    "    s3 = boto3.resource('s3')\n",
    "    json_data=df_copy.to_json(orient='records')\n",
    "    key=\"{}/{}.json\".format(folder, stock)\n",
    "    s3object = s3.Object('stock.etl', key)\n",
    "    s3object.put(Body=(bytes(json.dumps(json_data).encode('UTF-8'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e1c312f8814416c87369c268a0c325b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "\n",
    "def transformation_save_stock(stock_df, stock_symbol):\n",
    "    # First Keep useful information from stock price tables (Date, close and volume), forward fill missing values. \n",
    "    stock_price_df=stock_df.copy()\n",
    "    stock_price_df.drop(['Open','High','Low', 'Close'], axis=1, inplace=True)\n",
    "    stock_price_df.fillna(method='ffill')\n",
    "    stock_price_df.rename(columns={'Adj Close':'Close'}, inplace=True)\n",
    "    \n",
    "    \n",
    "    # Adding daily return (%), stock_rise (1, 0 if drop), technical indicators \n",
    "    stock_price_df['daily_return']=stock_price_df[['Close']]/stock_price_df[['Close']].shift(1)-1\n",
    "    stock_price_df=get_bbands(stock_price_df, 10)\n",
    "    stock_price_df=get_SMA(stock_price_df, 10)\n",
    "    stock_price_df=get_EMA(stock_price_df, 10)\n",
    "    stock_price_df=get_ROC(stock_price_df, 1)\n",
    "    stock_price_df['stock_rise']=np.where(stock_price_df['daily_return']>0, 1, 0)\n",
    "    \n",
    "    # save stock data\n",
    "    today_date=datetime.datetime.now().strftime(\"%Y.%m.%d\")\n",
    "    save_to_s3(stock_price_df, stock_symbol, \"current/{}\".format(today_date))\n",
    "    \n",
    "def transformation_save_news(news_df):      \n",
    "   # process news data\n",
    "    news_df_copy=news_df.copy()\n",
    "    news_df_copy['Rank']=news_df_copy['score'].rank(method='dense', ascending=False).astype(int)\n",
    "    news_df_copy.columns=['News', 'Score', 'Date', 'Rank']\n",
    "    news_df_copy=news_df_copy[['Date', 'Rank', 'Score', 'News']] \n",
    "    \n",
    "    # save news data\n",
    "    save_to_s3(news_df_copy, \"24hrNews\" \"current/{}\".format(today_date))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Data Quality checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First theck the output of the historic ETL. The result should be 7163 files (generated from 7163 stocks in raw zip file- stock folder) and the size of the smallest file should be larger than 0B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cec6e04af6c47aba420e95979c85e90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import commands\n",
    "\n",
    "\n",
    "def data_quality_check(folder, n_files):\n",
    "    output=os.system(\"aws s3 ls s3://stock.etl/{}/ --recursive | wc -l\".format(folder))\n",
    "    if (output!=n_files):\n",
    "        raise ValueError('Data quality check failed: file number not match')\n",
    "    status, output = commands.getstatusoutput(\"aws s3api list-objects-v2 --bucket stock.etl --prefix {} --output text --query 'sort_by(Contents,&Size)[0].Size'\".format(folder))\n",
    "    if (int(output[0]))<=0:\n",
    "        raise ValueError('Data quality check failed: contains empty file')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function used for DAGs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy the functions below for DAG python file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcdfef2f38c34fefa4bae9fe2fbefc61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import pyarrow\n",
    "import datetime\n",
    "import praw\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "def download_current_stocks_to_df(stocks, ndays):\n",
    "    end=datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    start=(datetime.datetime.now()-datetime.timedelta(days=ndays)).strftime(\"%Y-%m-%d\")\n",
    "    stock_dict={}\n",
    "    for symbol in stocks:\n",
    "        df_symbol=yf.download(symbol,start,end,progress=False)\n",
    "        stock_dict.update({symbol:df_symbol})\n",
    "    return stock_dict\n",
    "\n",
    "def get_24hr_news():\n",
    "    reddit = praw.Reddit(client_id='FbxkAEhvb7pxbg', \\\n",
    "                     client_secret='zyl8WnU9X5rr7y5_EeGUVj994kA', \\\n",
    "                     user_agent='topnewsscraper', \\\n",
    "                     username='xintao0202', \\\n",
    "                     password='zangma53@198422')\n",
    "    subreddit = reddit.subreddit('worldnews')\n",
    "    top_subreddit = subreddit.top(\"day\")\n",
    "    topics_dict = { \"title\":[], \"score\":[], \"created\": []}\n",
    "    \n",
    "    for submission in top_subreddit:\n",
    "        topics_dict[\"title\"].append(submission.title)\n",
    "        topics_dict[\"score\"].append(submission.score)\n",
    "    #     topics_dict[\"id\"].append(submission.id)\n",
    "    #     topics_dict[\"url\"].append(submission.url)\n",
    "    #     topics_dict[\"comms_num\"].append(submission.num_comments)\n",
    "        topics_dict[\"created\"].append(datetime.datetime.fromtimestamp(submission.created))\n",
    "    #     topics_dict[\"body\"].append(submission.selftext)\n",
    "    \n",
    "    topics_df = pd.DataFrame(topics_dict)\n",
    "    return topics_df\n",
    "\n",
    "def transformation_save_stock(stock_df, stock_symbol):\n",
    "    # First Keep useful information from stock price tables (Date, close and volume), forward fill missing values. \n",
    "    stock_price_df=stock_df.copy()\n",
    "    stock_price_df.drop(['Open','High','Low', 'Close'], axis=1, inplace=True)\n",
    "    stock_price_df.fillna(method='ffill')\n",
    "    stock_price_df.rename(columns={'Adj Close':'Close'}, inplace=True)\n",
    "    \n",
    "    \n",
    "    # Adding daily return (%), stock_rise (1, 0 if drop), technical indicators \n",
    "    stock_price_df['daily_return']=stock_price_df[['Close']]/stock_price_df[['Close']].shift(1)-1\n",
    "    stock_price_df=get_bbands(stock_price_df, 10)\n",
    "    stock_price_df=get_SMA(stock_price_df, 10)\n",
    "    stock_price_df=get_EMA(stock_price_df, 10)\n",
    "    stock_price_df=get_ROC(stock_price_df, 1)\n",
    "    stock_price_df['stock_rise']=np.where(stock_price_df['daily_return']>0, 1, 0)\n",
    "    \n",
    "    # save stock data\n",
    "    today_date=datetime.datetime.now().strftime(\"%Y.%m.%d\")\n",
    "    save_to_s3(stock_price_df, stock_symbol, \"current/stocks/{}\".format(today_date))\n",
    "    \n",
    "def transformation_save_news(news_df):      \n",
    "   # process news data\n",
    "    news_df_copy=news_df.copy()\n",
    "    news_df_copy['Rank']=news_df_copy['score'].rank(method='dense', ascending=False).astype(int)\n",
    "    news_df_copy.columns=['News', 'Score', 'Date', 'Rank']\n",
    "    news_df_copy=news_df_copy[['Date', 'Rank', 'Score', 'News']] \n",
    "    \n",
    "    # save news data\n",
    "    save_to_s3(news_df_copy, \"24hrNews\" \"current/news/{}\".format(today_date))\n",
    "\n",
    "def current_stocks_etl(list_of_stocks, ndays):\n",
    "    stocks_dict=download_current_stocks_to_df(list_of_stocks, ndays)\n",
    "    for key, value in stocks_dict.items():\n",
    "        stock_name=key.upper()\n",
    "        transformation_save_stock(value, stock_name)\n",
    "    \n",
    "def current_news_etl():\n",
    "    topics_df=get_24hr_news()\n",
    "    transformation_save_news(topics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
